{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_data = pd.read_csv('CA_data.csv')\n",
    "\n",
    "columns = ['Weather Vehicle 1', 'Lighting Vehicle 1', 'Roadway Surface Vehicle 1', 'Movement Preceding Collision Vehicle 1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Weather Vehicle 1\n",
      "Clear             265\n",
      "Cloudy             29\n",
      "Raining            10\n",
      "Fog/Visibility      3\n",
      "Wind                3\n",
      "Slippery            1\n",
      "Dark                1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Lighting Vehicle 1\n",
      "Daylight                                227\n",
      "Dark w Street-lights                     76\n",
      "Dusk/Dawn                                 5\n",
      "No unusual conditions                     2\n",
      "Dark w Non-functioning Street-lights      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Roadway Surface Vehicle 1\n",
      "Dry                    286\n",
      "Wet                     14\n",
      "Slippery                 8\n",
      "Other                    1\n",
      "Proceeding Straight      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Movement Preceding Collision Vehicle 1\n",
      "Stopped                                130\n",
      "Proceeding Straight                     91\n",
      "Slowing/Stopping                        19\n",
      "Making Right Turn                       15\n",
      "Making Left Turn                        12\n",
      "Parking                                 10\n",
      "Backing                                  8\n",
      "Changing Lanes                           5\n",
      "Other                                    5\n",
      "Entrering Traffic                        3\n",
      "Parking Manuever                         3\n",
      "Making U turn                            1\n",
      "Parking Manuerver                        1\n",
      "Parked                                   1\n",
      "Passing Other Vehicle                    1\n",
      "Xing into opposing lane                  1\n",
      "Making Right Turn, Slowing/Stopping      1\n",
      "Stopped, Merging                         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# dropping columns with null data\n",
    "for col in columns:\n",
    "    print(\"\\n\")\n",
    "    CA_data.drop(CA_data[CA_data[col] == 'Not Available'].index, inplace=True)\n",
    "    print(CA_data[col].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping data\n",
    "\n",
    "#### Column Weather Vehicle 1\n",
    "We are grouping Fog/visiblity with Dark because they are visual impariements\\\n",
    "We are grouping slippery, wind with raining because when it rains, it usally reults in slipperiness and sometimes wind\\\n",
    "\n",
    "#### Lighting Vehicle 1\n",
    "Grouping no unusla condition and daylight b/c they basically the same\\\n",
    "Grouping Dusk/dawn with dark with street lights b/c they are relatively similar conditions\\\n",
    "\n",
    "#### Movement Preceding Collision Vehicle 1\n",
    "Wet roads = slippery roads\\\n",
    "Dropped other and proceeding straight b/c they dont provide much value\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weather Vehicle 1\n",
      "Clear                  261\n",
      "Cloudy                  28\n",
      "Raining                 11\n",
      "Fog/Visibility/Dark      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Lighting Vehicle 1\n",
      "Daylight                224\n",
      "Dark w Street-lights     79\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Roadway Surface Vehicle 1\n",
      "Dry    283\n",
      "Wet     20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Movement Preceding Collision Vehicle 1\n",
      "Stopped                151\n",
      "Proceeding Straight     91\n",
      "Turning                 29\n",
      "Parking                 11\n",
      "Highway movement        10\n",
      "Backing                  8\n",
      "Parking Manuever         3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# grouping less frequent data \n",
    "CA_data['Weather Vehicle 1'].replace(['Fog/Visibility', 'Dark'], 'Fog/Visibility/Dark', inplace=True)\n",
    "CA_data['Weather Vehicle 1'].replace(['Slippery', 'Wind'], 'Raining', inplace=True)\n",
    "\n",
    "CA_data['Lighting Vehicle 1'].replace(['No unusual condition'], 'Daylight', inplace=True)\n",
    "CA_data['Lighting Vehicle 1'].replace(['Dusk/Dawn'], 'Dark w Street-lights', inplace=True)\n",
    "\n",
    "\n",
    "CA_data['Roadway Surface Vehicle 1'].replace(['Slippery'], 'Wet', inplace=True)\n",
    "CA_data.drop(CA_data[(CA_data['Roadway Surface Vehicle 1'] == 'Other') | (CA_data['Roadway Surface Vehicle 1'] == 'Proceeding Straight')].index, inplace=True)\n",
    "\n",
    "CA_data['Movement Preceding Collision Vehicle 1'].replace(['Making Right Turn', 'Making Left Turn', 'Making U turn', 'Making Right Turn, Slowing/Stopping'], 'Turning', inplace=True)\n",
    "CA_data['Movement Preceding Collision Vehicle 1'].replace(['Changing Lanes', 'Entering Traffic', 'Entrering Traffic','Xing into opposing lane', 'Passing Other Vehicle'], 'Highway movement', inplace=True)\n",
    "CA_data['Movement Preceding Collision Vehicle 1'].replace(['Slowing/Stopping', 'Stopped in Traffic', 'Parked', 'Stopped, Merging'], 'Stopped', inplace=True)\n",
    "CA_data['Movement Preceding Collision Vehicle 1'].replace(['Parking Manuerver'], 'Parking', inplace=True)\n",
    "CA_data.drop(CA_data[(CA_data['Movement Preceding Collision Vehicle 1'] == 'Other')].index, inplace=True)\n",
    "\n",
    "\n",
    "for col in columns:\n",
    "    print()\n",
    "    print(CA_data[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode our new columns\n",
    "encoded_CA_data = pd.get_dummies(CA_data, columns=columns, prefix='encoded_')\n",
    "encoded_columns = encoded_CA_data.columns[encoded_CA_data.columns.str.startswith('encoded_')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle Damage\n",
      "1    217\n",
      "3     53\n",
      "2     49\n",
      "0      8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoded_CA_data.drop(encoded_CA_data[(encoded_CA_data['Vehicle Damage'] == 'Not Available')].index, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_CA_data['Vehicle Damage'] = label_encoder.fit_transform(encoded_CA_data['Vehicle Damage'])\n",
    "\n",
    "print(encoded_CA_data['Vehicle Damage'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = encoded_CA_data[encoded_columns]\n",
    "y = encoded_CA_data['Vehicle Damage']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vehicle Damage\n",
       "1    217\n",
       "3     53\n",
       "2     49\n",
       "0      8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65957447, 0.63829787, 0.74468085, 0.82978723, 0.80851064,\n",
       "       0.76086957, 0.67391304])"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "scores = cross_val_score(clf, X, y, cv=7)\n",
    "\n",
    "scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_channels, 6)\n",
    "        self.fc2 = nn.Linear(6, 4)\n",
    "        self.fc3 = nn.Linear(4, output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vehicle Damage\n",
       "1    174\n",
       "3     41\n",
       "2     40\n",
       "0      6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.values\n",
    "X_test_np = X_test.values\n",
    "y_train_np = y_train.values\n",
    "y_test_np = y_test.values\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 4\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = FNN(X_train_tensor.shape[1], y.value_counts().shape[0])\n",
    "print(X_train_tensor.shape[1], y.value_counts().shape[0])\n",
    "device = 'mps'\n",
    "model.to(device)\n",
    "\n",
    "# hyper parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.363842248916626\n",
      "Epoch [2/100], Loss: 1.3598623275756836\n",
      "Epoch [3/100], Loss: 1.3557498455047607\n",
      "Epoch [4/100], Loss: 1.3516643047332764\n",
      "Epoch [5/100], Loss: 1.3476084470748901\n",
      "Epoch [6/100], Loss: 1.3435776233673096\n",
      "Epoch [7/100], Loss: 1.3395769596099854\n",
      "Epoch [8/100], Loss: 1.3356046676635742\n",
      "Epoch [9/100], Loss: 1.3316713571548462\n",
      "Epoch [10/100], Loss: 1.3277736902236938\n",
      "Epoch [11/100], Loss: 1.3239063024520874\n",
      "Epoch [12/100], Loss: 1.3200697898864746\n",
      "Epoch [13/100], Loss: 1.3162603378295898\n",
      "Epoch [14/100], Loss: 1.312514066696167\n",
      "Epoch [15/100], Loss: 1.3088107109069824\n",
      "Epoch [16/100], Loss: 1.305137276649475\n",
      "Epoch [17/100], Loss: 1.3014858961105347\n",
      "Epoch [18/100], Loss: 1.2978638410568237\n",
      "Epoch [19/100], Loss: 1.2942626476287842\n",
      "Epoch [20/100], Loss: 1.2906603813171387\n",
      "Epoch [21/100], Loss: 1.287085771560669\n",
      "Epoch [22/100], Loss: 1.2835372686386108\n",
      "Epoch [23/100], Loss: 1.2800122499465942\n",
      "Epoch [24/100], Loss: 1.2765142917633057\n",
      "Epoch [25/100], Loss: 1.2730375528335571\n",
      "Epoch [26/100], Loss: 1.2695937156677246\n",
      "Epoch [27/100], Loss: 1.2661792039871216\n",
      "Epoch [28/100], Loss: 1.2628059387207031\n",
      "Epoch [29/100], Loss: 1.2594774961471558\n",
      "Epoch [30/100], Loss: 1.2561715841293335\n",
      "Epoch [31/100], Loss: 1.2529277801513672\n",
      "Epoch [32/100], Loss: 1.2497984170913696\n",
      "Epoch [33/100], Loss: 1.2467024326324463\n",
      "Epoch [34/100], Loss: 1.2436532974243164\n",
      "Epoch [35/100], Loss: 1.2406153678894043\n",
      "Epoch [36/100], Loss: 1.2375658750534058\n",
      "Epoch [37/100], Loss: 1.2345231771469116\n",
      "Epoch [38/100], Loss: 1.2315318584442139\n",
      "Epoch [39/100], Loss: 1.2285786867141724\n",
      "Epoch [40/100], Loss: 1.2257490158081055\n",
      "Epoch [41/100], Loss: 1.2230503559112549\n",
      "Epoch [42/100], Loss: 1.220368504524231\n",
      "Epoch [43/100], Loss: 1.2177053689956665\n",
      "Epoch [44/100], Loss: 1.2150837182998657\n",
      "Epoch [45/100], Loss: 1.2124848365783691\n",
      "Epoch [46/100], Loss: 1.2098875045776367\n",
      "Epoch [47/100], Loss: 1.207309603691101\n",
      "Epoch [48/100], Loss: 1.2047431468963623\n",
      "Epoch [49/100], Loss: 1.20219087600708\n",
      "Epoch [50/100], Loss: 1.1996897459030151\n",
      "Epoch [51/100], Loss: 1.1972661018371582\n",
      "Epoch [52/100], Loss: 1.1949212551116943\n",
      "Epoch [53/100], Loss: 1.1925941705703735\n",
      "Epoch [54/100], Loss: 1.1902889013290405\n",
      "Epoch [55/100], Loss: 1.1881487369537354\n",
      "Epoch [56/100], Loss: 1.186355710029602\n",
      "Epoch [57/100], Loss: 1.1845762729644775\n",
      "Epoch [58/100], Loss: 1.18281090259552\n",
      "Epoch [59/100], Loss: 1.1810709238052368\n",
      "Epoch [60/100], Loss: 1.1793864965438843\n",
      "Epoch [61/100], Loss: 1.1776968240737915\n",
      "Epoch [62/100], Loss: 1.1760141849517822\n",
      "Epoch [63/100], Loss: 1.1743435859680176\n",
      "Epoch [64/100], Loss: 1.172619342803955\n",
      "Epoch [65/100], Loss: 1.1709010601043701\n",
      "Epoch [66/100], Loss: 1.1691880226135254\n",
      "Epoch [67/100], Loss: 1.167472004890442\n",
      "Epoch [68/100], Loss: 1.16575288772583\n",
      "Epoch [69/100], Loss: 1.1640303134918213\n",
      "Epoch [70/100], Loss: 1.1623077392578125\n",
      "Epoch [71/100], Loss: 1.1605935096740723\n",
      "Epoch [72/100], Loss: 1.158871054649353\n",
      "Epoch [73/100], Loss: 1.1571309566497803\n",
      "Epoch [74/100], Loss: 1.1553740501403809\n",
      "Epoch [75/100], Loss: 1.1536865234375\n",
      "Epoch [76/100], Loss: 1.1519948244094849\n",
      "Epoch [77/100], Loss: 1.150295615196228\n",
      "Epoch [78/100], Loss: 1.1485931873321533\n",
      "Epoch [79/100], Loss: 1.1468921899795532\n",
      "Epoch [80/100], Loss: 1.1451860666275024\n",
      "Epoch [81/100], Loss: 1.1434721946716309\n",
      "Epoch [82/100], Loss: 1.1417498588562012\n",
      "Epoch [83/100], Loss: 1.1400192975997925\n",
      "Epoch [84/100], Loss: 1.1382778882980347\n",
      "Epoch [85/100], Loss: 1.13652765750885\n",
      "Epoch [86/100], Loss: 1.1347700357437134\n",
      "Epoch [87/100], Loss: 1.1330033540725708\n",
      "Epoch [88/100], Loss: 1.131227731704712\n",
      "Epoch [89/100], Loss: 1.1294430494308472\n",
      "Epoch [90/100], Loss: 1.127650499343872\n",
      "Epoch [91/100], Loss: 1.1258503198623657\n",
      "Epoch [92/100], Loss: 1.1240423917770386\n",
      "Epoch [93/100], Loss: 1.12222421169281\n",
      "Epoch [94/100], Loss: 1.1203954219818115\n",
      "Epoch [95/100], Loss: 1.1185576915740967\n",
      "Epoch [96/100], Loss: 1.1167116165161133\n",
      "Epoch [97/100], Loss: 1.114859700202942\n",
      "Epoch [98/100], Loss: 1.1129999160766602\n",
      "Epoch [99/100], Loss: 1.1111128330230713\n",
      "Epoch [100/100], Loss: 1.1091896295547485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    inputs, targets = X_train_tensor.to(device), y_train_tensor.to(device)\n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "    outputs = model(inputs)  # Forward pass\n",
    "    loss = criterion(outputs, targets)  # Compute the loss\n",
    "    loss.backward()  # Backward pass (compute gradients)\n",
    "    optimizer.step()  # Update the weights\n",
    "\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6515151515151515\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test data\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs, targets = X_test_tensor.to(device), y_test_tensor.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = accuracy_score(predicted.cpu(), targets.cpu())\n",
    "    \n",
    "    print(f'Test Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
